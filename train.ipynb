{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50e23e2-fcc7-43ae-b0e4-9ecaae00129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e2fe5c-7b44-4330-9b0a-a5fc9388b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"경계\" : [1, 0, 0, 0],\n",
    "    \"주의\": [0, 1, 0, 0],\n",
    "    \"보통\": [0, 0, 1, 0],\n",
    "    \"낮음\": [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        self.x = []\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        for i in range(2, 6+1):\n",
    "            col = df.iloc[:, i].values\n",
    "            self.mean.append(col.mean())\n",
    "            self.std.append(col.std())\n",
    "            self.x.append((col - col.mean())/col.std())\n",
    "        \n",
    "        self.y = df.iloc[:, 0].map(mapping).values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[0][index], self.x[1][index], self.x[2][index], self.x[3][index], self.x[4][index]])\n",
    "        # y = torch.LongTensor([np.argmax(self.y[index])])\n",
    "        y = torch.FloatTensor(self.y[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9174caa-2ce9-417e-a3c7-1758d046e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(5, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(16, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976cba92-588b-4776-aa4b-585c4e4d6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\"./dataset/dataset.xlsx\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc43b4cd-3ed6-4f5a-81cd-80b6e970a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atlasyang/anaconda3/envs/model_1/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7717cdf2-82d5-4b31-8612-ce42e7c7568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :   10, Cost : 0.446\n",
      "Epoch :   20, Cost : 0.440\n",
      "Epoch :   30, Cost : 0.438\n",
      "Epoch :   40, Cost : 0.436\n",
      "Epoch :   50, Cost : 0.437\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y_indices = torch.argmax(y, dim=1).to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss.item()\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e191655-d5d7-4299-9a8d-96051637efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87, total: 5760, correct: 4991\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(\"./dataset/test.xlsx\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in test_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(x)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == torch.argmax(y, 1)).sum().item()  # y를 view를 사용하여 1차원으로 변환하여 정확성 계산\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}, total: {total}, correct: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb839dfe-9bc7-474b-99d2-c50128d4ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce26cb6f-85be-4765-9251-4c42816c4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump((train_dataset.mean, train_dataset.std), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea45e66-3e93-4d64-aa65-dd13f35d1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_1_kernel",
   "language": "python",
   "name": "model_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50e23e2-fcc7-43ae-b0e4-9ecaae00129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e2fe5c-7b44-4330-9b0a-a5fc9388b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"경계\": [1,0,0,0],\n",
    "    \"주의\": [0,1,0,0],\n",
    "    \"보통\": [0,0,1,0],\n",
    "    \"낮음\": [0,0,0,1]\n",
    "}\n",
    "\n",
    "def calculate_weights_for_dataset(dataset):\n",
    "    class_counts = [0] * 4\n",
    "    for _, label in dataset:\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    class_weights = [1.0 / count for count in class_counts]\n",
    "\n",
    "    weights = [class_weights[label] for _, label in dataset]\n",
    "    return weights\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        self.x = []\n",
    "        self.mean = []\n",
    "        self.std = []\n",
    "        for i in range(2, 6+1):\n",
    "            col = df.iloc[:, i].values\n",
    "            self.mean.append(col.mean())\n",
    "            self.std.append(col.std())\n",
    "            self.x.append((col - col.mean())/col.std())\n",
    "        \n",
    "        self.y = df.iloc[:, 0].map(mapping).values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[0][index], self.x[1][index], self.x[2][index], self.x[3][index], self.x[4][index]])\n",
    "        y = torch.LongTensor([np.argmax(self.y[index])])\n",
    "        #y = torch.FloatTensor(self.y[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9174caa-2ce9-417e-a3c7-1758d046e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(16, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976cba92-588b-4776-aa4b-585c4e4d6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\"./dataset/dataset.xlsx\")\n",
    "weights = calculate_weights_for_dataset(train_dataset)\n",
    "sampler = WeightedRandomSampler(weights, len(train_dataset))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43b4cd-3ed6-4f5a-81cd-80b6e970a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717cdf2-82d5-4b31-8612-ce42e7c7568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y.squeeze())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss.item()\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e191655-d5d7-4299-9a8d-96051637efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8387, total: 5760, correct: 4831\n",
      "0 Accuracy: 0.8025, total: 81, correct: 65\n",
      "1 Accuracy: 0.7708, total: 144, correct: 111\n",
      "2 Accuracy: 0.8603, total: 544, correct: 468\n",
      "3 Accuracy: 0.8389, total: 4991, correct: 4187\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(\"./dataset/test.xlsx\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "ans=[0,0,0,0]\n",
    "wrong=[0,0,0,0]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in test_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(x)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y.squeeze()).sum().item()\n",
    "        for i in range(4):\n",
    "            ans[i] += ((predicted == i) & (y.squeeze() == i)).sum().item()\n",
    "            wrong[i] += ((predicted != i) & (y.squeeze() == i)).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}, total: {total}, correct: {correct}\")\n",
    "for i in range(4):\n",
    "    print(f\"{i} Accuracy: {ans[i]/(ans[i]+wrong[i]):.4f}, total: {ans[i]+wrong[i]}, correct: {ans[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0241c-f20b-4cad-8098-2c6ba17e756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bd2b6-a9a6-4416-a667-222afe293e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb839dfe-9bc7-474b-99d2-c50128d4ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce26cb6f-85be-4765-9251-4c42816c4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mean_std.pkl', 'wb') as f:\n",
    "    pickle.dump((train_dataset.mean, train_dataset.std), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea45e66-3e93-4d64-aa65-dd13f35d1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_1_kernel",
   "language": "python",
   "name": "model_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
